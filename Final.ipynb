{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69143dd-149d-4531-9c40-289e12f7840d",
   "metadata": {},
   "source": [
    "# House Hunters - HGTV\n",
    "\n",
    "\"House Hunters\" is a television show in which families are shown several homes and then choose one to purchase. Each episode is set in a specific city.\n",
    "\n",
    "Since its debut in 1999, the show has aired over 3,200 episodes. However, there is no official database that specifies the locations featured in each episode. \n",
    "\n",
    "**The episode descriptions do not explicitly state their locations. Here GPT is used to find out he locations**\n",
    "\n",
    "Utilizing the database created in this notebook, users can now locate episodes specific to a certain city. This is particularly useful for people considering relocating, as it provides them with actual video tours of neighborhoods, offering a glimpse into the housing market of the city.\n",
    "\n",
    "The actual episodes are not available here, but they can be accessed on various streaming platforms.\n",
    "\n",
    "All the data presented here was sourced from: https://www.hgtv.com/shows/house-hunters/episodes/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade68458-ceff-42a1-a0b5-7a8c337e1ebe",
   "metadata": {},
   "source": [
    "<div class='tableauPlaceholder' id='viz1706735029553' style='position: relative'><noscript><a href='#'><img alt='Dashboard 2 (3) ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;HH&#47;HH_2024&#47;Dashboard23&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='HH_2024&#47;Dashboard23' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;HH&#47;HH_2024&#47;Dashboard23&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /><param name='filter' value='publish=yes' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1706735029553');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else { vizElement.style.width='100%';vizElement.style.height='977px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac5f9cb-569a-4008-acf3-70695f5edd46",
   "metadata": {},
   "source": [
    "To interect with the data use the link below:\n",
    "\n",
    "https://public.tableau.com/views/HH_2024/Dashboard23?:language=en-US&publish=yes&:display_count=n&:origin=viz_share_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639b24f-0a2c-4057-b4f2-ecd5ae337815",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "- Retrieve data from the official website.\n",
    "- Utilize OpenAI's GPT to Infer locations based on episode descriptions.\n",
    "- Clean the data.\n",
    "- Visualize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e1c81-968e-4cd3-8c28-8d4ee95de1dd",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e679e-f062-4ddf-a8eb-735be11a4fbb",
   "metadata": {},
   "source": [
    "Imports and OpenAI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46aaea4f-57f0-4b89-8d4f-3b199b09f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570905c4-478e-4848-8b1f-6cba24706239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get openAI key\n",
    "def get_api_key(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "api_key = get_api_key('config.txt') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0ac44-e7ad-4a46-a8ba-c6b3ffb50a66",
   "metadata": {},
   "source": [
    "## Retrieve data from the official website\n",
    "- Navigate through all the pages to retrieve information on seasons, episodes, titles, and descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f98964-5531-4a96-8fd3-b6f992b7a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start URL\n",
    "url = 'https://www.hgtv.com/shows/house-hunters/episodes/1a'\n",
    "\n",
    "all_data = []\n",
    "\n",
    "while True:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    episode_info = soup.find_all('span', class_='m-EpisodeCard__a-AssetInfo')\n",
    "    description_elements = soup.find_all('p', class_='m-EpisodeCard__a-Description')\n",
    "\n",
    "    for ep, desc in zip(episode_info, description_elements):\n",
    "        text = ep.text.split(',')\n",
    "        if len(text) == 2:\n",
    "            season, episode = text\n",
    "            season = season.split(' ')[1]  # Extract season number\n",
    "            episode = episode.split(' ')[2]  # Extract episode number\n",
    "            description = desc.text.strip()\n",
    "            all_data.append({'Season': season, 'Episode': episode, 'Description': description})\n",
    "\n",
    "    # Find the \"Next\" button link\n",
    "    next_button = soup.find('a', class_='o-Pagination__a-Button o-Pagination__a-NextButton')\n",
    "    if next_button and 'href' in next_button.attrs:\n",
    "        url = 'https:' + next_button['href']\n",
    "        # Stop if the final URL is reached\n",
    "        if url.endswith('/episodes/246'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041b780-eea4-4b0d-b6f1-f82d13571e45",
   "metadata": {},
   "source": [
    "Save all the Raw data to an .xlsx file for Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86b68b-d63a-4d47-bfc2-cffe4f50c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to an Excel file\n",
    "file_path = \"full_data_HH.xlsx\"\n",
    "\n",
    "df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba9a3cf-19df-4f75-8c41-5a88da98cbd8",
   "metadata": {},
   "source": [
    "## OpenAI's GPT to Infer locations based on episode descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1f9fa1-241d-44b9-bae9-a1bbb3789af6",
   "metadata": {},
   "source": [
    "- Define base prompt\n",
    "- define answer fromat\n",
    "- provide title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e78b5-d956-488d-bcc2-d9776ae925b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(api_key)\n",
    "\n",
    "# Function to query GPT-3.5 with the new API\n",
    "def query_gpt3(title, description, counter):\n",
    "    prompt = (\n",
    "        f\"In this scenario, you are presented with a description of a TV show focused on house buyers. Your task is to discern, based on the provided information, the city and state (if applicable) in which the show is likely set. Your response should adhere to the format 'city, state, country.'\\n\"\n",
    "        f\"In cases where the city's identity remains uncertain, please indicate 'unknown' for the city. If you can identify the city but not the state or country, indicate the city's name, followed by 'unknown' for the state and country. It is crucial to maintain the correct order of 'city, state, country.'\\n\"\n",
    "        f\"Please provide a confident response regarding the city, and if any uncertainty persists, use 'unknown' for the city. Just give the answer in the desired format, no explanations:\\n\"\n",
    "        f\"title of episode: {title}\\n\"\n",
    "        f\"description of episode: {description}\\n\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=\"gpt-3.5-turbo\"\n",
    "    )\n",
    "\n",
    "    # Extracting the response text\n",
    "    response_text = response.choices[0].message.content\n",
    "\n",
    "    # Splitting the response text into city, state, and country\n",
    "    split_response = response_text.split(\", \")\n",
    "    city = split_response[0] if len(split_response) > 0 else \"unknown\"\n",
    "    state = split_response[1] if len(split_response) > 1 else \"unknown\"\n",
    "    country = split_response[2] if len(split_response) > 2 else \"unknown\"\n",
    "\n",
    "    # Print the result for tracking\n",
    "    print(f\"Response {counter}: {city}, {state}, {country}\")\n",
    "\n",
    "    return city, state, country\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"full_data_HH.xlsx\")\n",
    "\n",
    "# Process each row and store responses\n",
    "cities = []\n",
    "states = []\n",
    "countries = []\n",
    "counter = 1\n",
    "for index, row in df.iterrows():\n",
    "    city = row['City']  # Get the value in the \"City\" column\n",
    "    if city == \"unknown\":  # Check if the city is unknown\n",
    "        title = row['Title']\n",
    "        description = row['Description']\n",
    "        city, state, country = query_gpt3(title, description, counter)\n",
    "    else:\n",
    "        # If the city is not \"unknown,\" use the existing values from the DataFrame\n",
    "        state = row['State']\n",
    "        country = row['Country']\n",
    "        print(\"OK\")\n",
    "    \n",
    "    cities.append(city)\n",
    "    states.append(state)\n",
    "    countries.append(country)\n",
    "    counter += 1\n",
    "\n",
    "# Add responses to DataFrame\n",
    "df['City'] = cities\n",
    "df['State'] = states\n",
    "df['Country'] = countries\n",
    "\n",
    "# Optional: Save the DataFrame to a new Excel file\n",
    "df.to_excel(\"gpt3_round_1.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff0fbe-42e7-48e2-aac9-3313b2cd4828",
   "metadata": {},
   "source": [
    "### Clean the data\n",
    "- Do some cleaning...\n",
    "- Hardcoded some common mistakes\n",
    "- make another pass using GPT on bad results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155acce-15a7-40cf-90eb-038c1d68f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "input_file = \"gpt3_round_1.xlsx.xlsx\"\n",
    "output_file = \"gpt3_responses_full_revised.xlsx\"\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# 1. Remove '.' from the \"Country\" column\n",
    "df['Country'] = df['Country'].str.replace('.', '')\n",
    "\n",
    "# 2. Replace \"USA\" with \"United States\" in the \"Country\" column\n",
    "df['Country'] = df['Country'].replace('USA', 'United States')\n",
    "\n",
    "# 3. Replace \"country\" with \"unknown\" in the \"Country\" column\n",
    "df['Country'] = df['Country'].replace('country', 'unknown')\n",
    "\n",
    "# 4. Replace \"D.C.\" or \"DC\" with \"Washington D.C.\" in the \"State\" column\n",
    "df['State'] = df['State'].replace(['D.C.', 'DC'], 'Washington D.C.')\n",
    "\n",
    "# 5. Replace \"Washington State\" with \"Washington\" in the \"State\" column\n",
    "df['State'] = df['State'].replace('Washington State', 'Washington')\n",
    "\n",
    "# 6. Replace \"Ill.\" or \"Illinois,United States.\" with \"Illinois\" in the \"State\" column\n",
    "df['State'] = df['State'].replace(['Ill.', 'Illinois,United States.'], 'Illinois')\n",
    "\n",
    "# 7. Replace \"New York City\" with \"New York\" in the \"State\" column\n",
    "df['State'] = df['State'].replace('New York City', 'New York')\n",
    "\n",
    "# 8. Replace \"Maryland-Virginia\" with \"Maryland\" in the \"State\" column\n",
    "df['State'] = df['State'].replace('Maryland-Virginia', 'Maryland')\n",
    "\n",
    "# 9. Replace \"Ga.\" with \"Georgia\" in the \"State\" column\n",
    "df['State'] = df['State'].replace('Ga.', 'Georgia')\n",
    "\n",
    "# 10. Replace \"state\" with \"unknown\" in the \"State\" column\n",
    "df['State'] = df['State'].replace('state', 'unknown')\n",
    "\n",
    "# Save the revised data to a new Excel file\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"Revised data saved to\", output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1f0f5-7b87-483a-88ce-92d77922cf4c",
   "metadata": {},
   "source": [
    "Use GPT again on \"unknown results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac002c-3d30-4fc8-b46a-c1a464adc2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(api_key)\n",
    "\n",
    "# Function to query GPT-3.5 with the new API\n",
    "def query_gpt3(title, description, counter):\n",
    "    prompt = (\n",
    "        f\"In this scenario, you are presented with a description of a TV show focused on house buyers. Your task is to discern, based on the provided information, the city and state (if applicable) in which the show is likely set. Your response should adhere to the format 'city, state, country.'\\n\"\n",
    "        f\"In cases where the city's identity remains uncertain, please indicate 'unknown' for the city. If you can identify the city but not the state or country, indicate the city's name, followed by 'unknown' for the state and country. It is crucial to maintain the correct order of 'city, state, country.'\\n\"\n",
    "        f\"Please provide a confident response regarding the city, and if any uncertainty persists, use 'unknown' for the city. Just give the answer in the desired format, no explanations:\\n\"\n",
    "        f\"title of episode: {title}\\n\"\n",
    "        f\"description of episode: {description}\\n\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=\"gpt-3.5-turbo\"\n",
    "    )\n",
    "\n",
    "    # Extracting the response text\n",
    "    response_text = response.choices[0].message.content\n",
    "\n",
    "    # Splitting the response text into city, state, and country\n",
    "    split_response = response_text.split(\", \")\n",
    "    city = split_response[0] if len(split_response) > 0 else \"unknown\"\n",
    "    state = split_response[1] if len(split_response) > 1 else \"unknown\"\n",
    "    country = split_response[2] if len(split_response) > 2 else \"unknown\"\n",
    "\n",
    "    # Print the result for tracking\n",
    "    print(f\"Response {counter}: {city}, {state}, {country}\")\n",
    "\n",
    "    return city, state, country\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"gpt3_responses_full_revised.xlsx\")\n",
    "\n",
    "# Process each row and store responses\n",
    "cities = []\n",
    "states = []\n",
    "countries = []\n",
    "counter = 1\n",
    "for index, row in df.iterrows():\n",
    "    city = row['City']  # Get the value in the \"City\" column\n",
    "    if city == \"unknown\":  # Check if the city is unknown\n",
    "        title = row['Title']\n",
    "        description = row['Description']\n",
    "        city, state, country = query_gpt3(title, description, counter)\n",
    "    else:\n",
    "        # If the city is not \"unknown,\" use the existing values from the DataFrame\n",
    "        state = row['State']\n",
    "        country = row['Country']\n",
    "        print(\"OK\")\n",
    "    \n",
    "    cities.append(city)\n",
    "    states.append(state)\n",
    "    countries.append(country)\n",
    "    counter += 1\n",
    "\n",
    "# Add responses to DataFrame\n",
    "df['City'] = cities\n",
    "df['State'] = states\n",
    "df['Country'] = countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b5b9a7-b23b-4d65-8cc8-8c6d9f28e43d",
   "metadata": {},
   "source": [
    "Save final result for Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e49f1-0d6e-4f5f-84aa-7739e8ae8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"gpt3_round_3.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f73cb8-05e4-4970-8798-7570422838cb",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e8875-387c-452b-8fca-6bf81e65e404",
   "metadata": {},
   "source": [
    "The link below is the best way to visualize and interact with the data. It leverages Tableau Public.\n",
    "\n",
    "https://public.tableau.com/views/HH_2024/Dashboard23?:language=en-US&publish=yes&:display_count=n&:origin=viz_share_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8415a-b4c1-4531-aa95-c79062b171c9",
   "metadata": {},
   "source": [
    "<div class='tableauPlaceholder' id='viz1706735029553' style='position: relative'><noscript><a href='#'><img alt='Dashboard 2 (3) ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;HH&#47;HH_2024&#47;Dashboard23&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='HH_2024&#47;Dashboard23' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;HH&#47;HH_2024&#47;Dashboard23&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /><param name='filter' value='publish=yes' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1706735029553');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else { vizElement.style.width='100%';vizElement.style.height='977px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
